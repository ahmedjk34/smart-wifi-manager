# Smart WiFi Rate Adaptation ML Pipeline

A comprehensive machine learning pipeline for intelligent WiFi rate adaptation using ns-3 simulation data. This project implements class weight-based training instead of aggressive downsampling to preserve realistic network conditions while handling class imbalance effectively.

## ğŸ¯ Project Overview

This project develops machine learning models for WiFi rate adaptation that can intelligently select optimal transmission rates based on real-time network conditions. Unlike traditional approaches that force artificial class balance, our pipeline preserves realistic network distributions while using class weights to ensure minority classes receive appropriate attention during training.

## ğŸ“Š Key Achievements

- **412,000 training samples** with 42 engineered features
- **Class weight-based imbalance handling** preserving realistic network distributions
- **3 oracle strategies**: Conservative, Balanced, and Aggressive rate adaptation
- **12 synthetic edge case scenarios** for robust model training
- **6 network context classifications** covering all WiFi conditions

## ğŸ—ï¸ Architecture

### Data Processing Pipeline

```

Raw WiFi Data â†’ Cleaning â†’ Feature Engineering â†’ Context Classification â†’ Oracle Labels â†’ Class Weights â†’ ML Training

```

### Network Context Classification

- **Emergency Recovery**: SNR < 10dB, Success < 50%, Consecutive failures â‰¥ 3
- **Poor Unstable**: SNR < 15dB, High variance conditions
- **Marginal Conditions**: SNR < 20dB, Success < 80%
- **Good Unstable**: High SNR variance but decent performance
- **Good Stable**: Stable conditions with good performance
- **Excellent Stable**: SNR > 25dB, Success > 90%, Low variance

## ğŸ“ Project Structure

```

smart-wifi-manager/
â”œâ”€â”€ python_files/
â”‚ â”œâ”€â”€ 3_enhanced_ml_labeling_prep.py # Data prep with class weights
â”‚ â”œâ”€â”€ ultimate_ml_training_with_class_weights.py # Training pipeline
â”‚ â”œâ”€â”€ model_artifacts/
â”‚ â”‚ â””â”€â”€ class_weights.json # Computed class weights
â”‚ â””â”€â”€ logs/ # Training logs
â”œâ”€â”€ smart-v3-ml-cleaned.csv # Cleaned WiFi data
â”œâ”€â”€ smart-v3-ml-enriched.csv # ML-ready dataset
â”œâ”€â”€ step3_rf_rateIdx_model_FIXED.joblib # Trained model
â”œâ”€â”€ step3_scaler_FIXED.joblib # Feature scaler
â””â”€â”€ README.md # This file

```

## ğŸ”¬ Technical Innovation: Class Weights vs Downsampling

### The Problem with Traditional Approaches

Most ML pipelines for imbalanced data use aggressive downsampling:

- âŒ Forces artificial 1:1 class balance
- âŒ Destroys realistic network patterns
- âŒ Removes valuable majority class information
- âŒ Poor generalization to real-world scenarios

### Our Solution: Intelligent Class Weighting

```python
# Example class weights for rateIdx
rateIdx Class Weights:
  0: 0.254   # Common rates (low weight)
  1: 0.507
  5: 0.509
  2: 33.204  # Rare rates (high weight)
  3: 59.745
  4: 55.317
  6: 29.838
  7: 29.855
```

### Benefits:

- âœ… Preserves realistic 49.2% vs 0.2% rate distributions
- âœ… Rare scenarios get 30-60x more training attention
- âœ… No data loss - keeps all valuable samples
- âœ… Better real-world generalization

## ğŸ“ˆ Dataset Statistics

### Final Dataset Composition

- **Total Samples**: 412,000
- **Features**: 42 engineered features
- **Real Data**: 400,000 samples
- **Synthetic Edge Cases**: 12,000 samples
- **Network Contexts**: 6 classifications

### Class Distribution (rateIdx)

| Rate | Samples | Percentage | Class Weight |
| ---- | ------- | ---------- | ------------ |
| 0    | 202,522 | 49.2%      | 0.254        |
| 1    | 101,543 | 24.6%      | 0.507        |
| 5    | 101,140 | 24.5%      | 0.509        |
| 2    | 1,551   | 0.4%       | 33.204       |
| 6    | 1,726   | 0.4%       | 29.838       |
| 7    | 1,725   | 0.4%       | 29.855       |
| 3    | 862     | 0.2%       | 59.745       |
| 4    | 931     | 0.2%       | 55.317       |

### Network Context Distribution

- **Poor Unstable**: 402,602 (97.8%) - Realistic WiFi conditions
- **Emergency Recovery**: 3,202 (0.8%) - Critical scenarios
- **Marginal Conditions**: 2,077 (0.5%) - Borderline performance
- **Good Stable**: 2,050 (0.5%) - Optimal conditions
- **Excellent Stable**: 1,053 (0.3%) - Perfect conditions
- **Good Unstable**: 1,016 (0.2%) - High performance, variable conditions

## ğŸ› ï¸ Usage

### 1. Data Preparation

```bash
python 3_enhanced_ml_labeling_prep.py
```

**Features:**

- Loads raw WiFi simulation data
- Applies sanity filtering and outlier removal
- Generates network context classifications
- Creates oracle labels (conservative/balanced/aggressive)
- Computes class weights for imbalanced learning
- Generates synthetic edge cases
- Exports ML-ready dataset

### 2. Model Training

```bash
python ultimate_ml_training_with_class_weights.py
```

**Features:**

- Chunked loading for large datasets (RAM-efficient)
- Stratified train/validation/test splits
- Feature scaling with StandardScaler
- Random Forest with class weights
- Comprehensive evaluation metrics
- Model and scaler persistence

### 3. Model Artifacts

Generated files:

- `step3_rf_rateIdx_model_FIXED.joblib` - Trained Random Forest
- `step3_scaler_FIXED.joblib` - Feature scaler
- `class_weights.json` - Computed class weights
- Training logs and documentation

## ğŸ“Š Key Features

### Engineered Features (42 total)

- **SNR Metrics**: lastSnr, snrFast, snrSlow, snrVariance, snrStabilityIndex
- **Success Metrics**: shortSuccRatio, medSuccRatio, consecutiveSuccess/Failure
- **Throughput**: recentThroughputTrend, packetLossRate, retrySuccessRatio
- **Rate Stability**: rateStabilityScore, timeSinceLastRateChange, recentRateChanges
- **Network State**: queueLen, mobilityMetric, channelWidth, offeredLoad
- **Decision Context**: severity, confidence, optimalRateDistance

### Oracle Strategies

1. **Conservative**: Prioritizes reliability over throughput
2. **Balanced**: Balances reliability and performance
3. **Aggressive**: Maximizes throughput with acceptable risk

### Synthetic Edge Cases (12 scenarios)

- High rate failure scenarios
- Low rate recovery situations
- SNR volatility conditions
- Queue saturation events
- Mobility spike scenarios
- Persistent failure cases
- Sudden improvement conditions
- Consecutive success patterns
- Channel width changes
- Rate flip-flop behavior
- Low SNR success cases
- High SNR failure anomalies

## ğŸ¯ Model Performance Expectations

Based on the dataset quality and class weight approach:

- **Expected Validation Accuracy**: 85-92%
- **Training Time**: 5-15 minutes
- **Model Complexity**: Balanced Random Forest (120 estimators, depth 16)
- **Real-world Applicability**: High (preserved realistic distributions)

## ğŸ”§ Technical Requirements

```bash
# Core dependencies
pandas>=1.5.0
numpy>=1.20.0
scikit-learn>=1.1.0
joblib>=1.2.0

# Visualization (optional)
matplotlib>=3.5.0
seaborn>=0.11.0

# Progress tracking
tqdm>=4.64.0
```

## ğŸ“ Key Design Decisions

### 1. Class Weights Over Downsampling

**Rationale**: Network data imbalance is informative, not noise. Preserving realistic distributions while adjusting training weights yields better real-world performance.

### 2. Context-Aware Oracle Labels

**Rationale**: Different network conditions require different strategies. Emergency scenarios need conservative approaches, while stable conditions can afford aggressive optimization.

### 3. Synthetic Edge Case Generation

**Rationale**: Real data may lack critical failure scenarios. Synthetic generation ensures model robustness in edge conditions.

### 4. Multi-Strategy Training

**Rationale**: Different applications need different risk profiles. Training multiple oracle strategies provides deployment flexibility.

## ğŸš€ Results Summary

### Data Quality Metrics

- âœ… **Clean Data**: 412k samples, realistic feature ranges
- âœ… **Balanced Coverage**: All network contexts represented
- âœ… **Rich Features**: 42 engineered features capture WiFi complexity
- âœ… **Edge Case Coverage**: 12k synthetic scenarios for robustness

### Innovation Highlights

- ğŸ”¥ **Class Weight Revolution**: First WiFi rate adaptation using class weights vs downsampling
- ğŸ”¥ **Realistic Distributions**: Preserves 97.8% poor conditions vs 0.3% excellent (real WiFi!)
- ğŸ”¥ **Context Intelligence**: Network-aware oracle strategies
- ğŸ”¥ **Production Ready**: RAM-efficient, scalable pipeline

## ğŸ“ˆ Next Steps

1. **Model Validation**: Test trained model against ns-3 simulations
2. **Hyperparameter Tuning**: Optimize Random Forest parameters
3. **Alternative Algorithms**: Test Neural Networks with class weights
4. **Real-world Deployment**: Integrate with WiFi drivers/firmware
5. **Performance Monitoring**: Track model accuracy in production

## ğŸ¤ Contributing

This project demonstrates best practices for:

- Handling imbalanced time-series data
- Preserving realistic distributions in ML pipelines
- Context-aware feature engineering for network data
- Production-ready ML model training

## ğŸ“„ License

This project is part of advanced WiFi research and follows academic/research usage guidelines.

---

**Author**: ahmedjk34  
**Date**: September 22, 2025  
**Project**: Smart WiFi Rate Adaptation ML Pipeline  
**Innovation**: Class Weight-Based Training for Realistic Network ML Models

_"Preserving reality while learning from imbalance - the future of network machine learning."_

```

```
